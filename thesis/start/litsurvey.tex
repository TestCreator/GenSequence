%literature survey
The essence of the oracle problem is best captured in the definition of non-testable programs, provided by Weyuker:
\begin{quote}
A program should be considered non-testable [if] (1) there does not exist an oracle; (2) it is theoretically possible, but practically too difficult to determine the correct output~\cite{Chays:2000:FTD:347636.348954}
\end{quote}
There are a variety of reasons why the oracle does not exist or can be exercised in a practical capacity. Weyuker describes that some software systems are like magic calculators – they are meant to inform us of the answer. She additionally mentions that some programs produce output that is impossible to read, either because of its volume or complexity. Here lies the core of software testing challenges. It is impossible to solve for every oracle or be able to describe every detail of a complex oracle – every system is entirely different and no generic template could create a standardized oracle. However, it is possible to avoid oracles altogether, generate them partially, or give hints about what details are most important to check.

One method of avoiding oracles altogether is metamorphic testing, which exploits the relationships of different executions of different input data. For example, upon white box inspection of a system, testers can see that outputs should relate directly to their inputs. They may not know much else about the system, or what its output means, but they know what differences they should see upon two different executions . Upon a certain execution they get f(5) = 20, and since they know the input-output relates directly, then they should predict that f(6) > f(5). Though exceptional in avoiding oracles, ascertaining metamorphic relationships is as challenging as the oracle problem.

Other researchers have proposed methods that do not attempt to provide or calculate an oracle, but rather aid the tester, informed of the structure of the system, exactly what details she should watch and constrain about the oracle. This takes the form of determining, through a series of tests, which variables in the system are most effective in revealing faults or bad behavior, and then providing them to the tester to define the ``correct'' value. One research group used mutant generation to find which variables killed the most mutants and, therefore, found the most faults . An alternative solution identified chains of dependent variables using probabilistic substitution graphs to find the most important variables . These works make the best advances in the reducing the human effort needed to define and fulfill a complicated oracle.

Another group used Perlin noise as a data generator for images representing the spread of non-native pests in British forests. They layered multiple realistic images together and used spatial statistics to ``optimize'' their images. In other words, they identified traits from real test images, like a histogram of pixel values, and applied them to their own images to enforce similar traits. Most importantly, their tool generated images extremely efficiently and therefore quickly, making their tool exceptionally streamlined. However, their tool did not aim to provide any oracle information, and instead opted to using metamorphic relationships between real images and their fabricated images to find faults.

One group with members in Brazil and Luxembourg used their previous work on a method that identified how close test data approached synthetic bugs to create a new heuristic that ``finds'' data points that could reliably strongly kill the mutants in a program. Their approach works backwards by using a search scheme to identify data points at potential test candidates.


Random testing is not new, but it also is not very useful. Neither \textit{purely} random testing or purely random data generation is not strong enough to adequately test all branches of the code, nor does it provide any useful information about the test case itself or the data it contains. Consequently, constrained randomness, or using randomness in conjunction with other techniques, has gained the benefits of randomness' automation with the structure of other established testing methodologies. The biggest complaint of pure random testing is that of the distribution type typically implemented: uniform distribution, which is why Lu recommends sampling along sample-space partitions non-uniformly~\cite{Lu:2018:URS:3184558.3186240}, preferring uneven numbers of ``Random Node'' selections and ``Random Edge'' selections. Another generalized technique is that of continous feedback. Arcuri describes Adaptive Random Testing, which monitors the success of the result of a random test case, and then appropriately chooses the next input to be unlike the previous input to attempt to trigger a different result~\cite{Arcuri:2011:ART:2001420.2001452}. All input choices are random, but directed towards certain trends. Arcuri identified a primary problem with this technique in that it often finds repeat bugs and does not extend to as many situations that pure random test cases otherwise could have found. However, several recent  groups similarly use a continuous feedback loops to identify the next test cases but with greater control over random stepping so as to address Arcuri's concerns~\cite{Yatoh:2015:FRT:2771783.2771805,Hughes:2016:FMB:2896921.2896928,Sabor:2015:ART:2819261.2819271}.

Applying constraints on random data generation is particularly topical to areas of Machine Learning and Database-Driven applications. A team from Columbia University constructed a framework for generating test data for machine-learning models that produce ranking decisions on likely failability of a network of devices. Not only did their framework take in to account the number of examples and number of attributes of a dataset, it considered appearance of repeat values, missing entries, and partitioned categories of examples~\cite{Murphy:2007:PRT:1292414.1292425,Murphy:Kaiser}. However their tool only implemented uniform distribution and could only produce positive integers. This is a keystone feature that indicates the specialization of their framework, and makes extensibility to other applications of software testing nonexistent without significant refactoring. In regards to database-driven applications, there is a considerable lack of developing in testing. The typical approach of data generation is really quite limited in its power. That data really only passes synactic checks, like matching database schema descriptions, and general ``not null, unique, primary, and foreign key constraints'', which indicates that the links between data makes sense. The data is database-compliant, it does not have any mistakes, but it contains no semantic meaning. It does not exhibit any trends or patterns. The shortcomings of these applications influence the necessary features of my project.
